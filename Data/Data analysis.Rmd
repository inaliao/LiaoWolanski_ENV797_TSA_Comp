---
title: "Data wrangling"
author: "Ina Liao and Drew Wolanski"
date: "2024-03-25"
output: html_document
---

```{r Setup, include=FALSE}
knitr:::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=FALSE,fig.align = "center", dev = "cairo_pdf", fig.pos = "H")
```

```{r Install packages, message=FALSE}
#install.packages("lubridate")
#install.packages("ggplot2")
#install.packages("forecast")
#install.packages("here")
#install.packages("knitr")
#install.packages("kableExtra")
#install.packages("dplyr")
#install.packages("openxlsx")
#install.packages("ggthemes")
#install.packages("tidyr")
#install.packages("GGally")
#install.packages("tseries")
#install.packages("blorr")
#install.packages("car")
#install.packages("corrplot")
#install.packages("dlm")
#install.packages("randomForest")
#install.packages("Kendall")
library(lubridate)
library(ggplot2)
library(forecast) 
library(here)
library(knitr)
library(kableExtra)
library(dplyr)
library(openxlsx)
library(ggthemes)
library(tidyr)
library(Kendall)
library(GGally)
library(trend)
library(tseries)
library(blorr)   
library(lmtest) 
library(car)
library(cowplot)
library(corrplot)
library(dlm)
library(randomForest)
library(e1071) #for SVM
```

```{r Import Data, echo=TRUE, results='hide'}
here()
df_load<-read.csv(here('Data/Processed/load_processed.csv'),stringsAsFactors = TRUE,skip=0,header=TRUE)
df_temp<-read.csv(here('Data/Processed/temp_processed.csv'),stringsAsFactors = TRUE,skip=0,header=TRUE)
df_humid<-read.csv(here('Data/Processed/humid_processed.csv'),stringsAsFactors = TRUE,skip=0,header=TRUE)
```

```{r Filter data}
#date
df_load$date<-ymd(df_load$date)
df_temp$date<-ymd(df_temp$date)
df_humid$date<-ymd(df_humid$date)

#selected needed column
df_load_processed<-df_load%>%
  select(meter_id,date,daily_mean)
df_temp_processed<-df_temp[,2:28]
df_humid_processed<-df_humid[,2:28]

#as numaric
for (i in 2:27){
  df_temp_processed[,i]<-as.numeric(df_temp_processed[,i])
  df_humid_processed[,i]<-as.numeric(df_humid_processed[,i])
}
```

```{r Create time series object}
#load
msts_load<-msts(df_load_processed[,3],seasonal.periods=c(7,365),start =c(2005,01,01), end=c(2011,05,31))
autoplot(msts_load)
```
```{r Temp and humidity}
df_temp_data<-df_temp_processed[,2:27]
df_temp_processed %>%
  mutate(daily_mean=rowMeans(df_temp_data, na.rm = TRUE)) %>%
  select(date,daily_mean) 

df_humid_data<-df_humid_processed[,2:27]
df_humid_processed %>%
  mutate(daily_mean=rowMeans(df_humid_data, na.rm = TRUE)) %>%
  select(date,daily_mean) 

```

```{r ACF and PACF}
#load
par(mfrow=c(1,2))
Acf(msts_load,lag.max=40,main=paste("ACF for load"),ylim=c(-0.5,1))
Pacf(msts_load,lag.max=40,main=paste("PACF for load"),ylim=c(-0.5,1))
```



```{r Detrend and deseason}
#decompose 
load_decompose<-decompose(msts_load)
plot(load_decompose)

#deseason
load_deseason<-seasadj(load_decompose)
plot_grid(
  autoplot(load_deseason),
  autoplot(Acf(load_deseason,plot=FALSE,lag.max=40)),
  autoplot(Pacf(load_deseason,plot=FALSE,lag.max=40)),
  nrow=1
)
```

```{r Stationary test}
#Mann-Kendall
summary(MannKendall(load_deseason)) #reject the null hypothesis, supporting the presence of a trend

#seasonal Mann-Kendall
#correction: calculate monthly average 
trend::smk.test(load_deseason) 


#ADF test
print(adf.test(load_deseason,alternative = "stationary")) #reject the null hypothesis, the trend is stationary 
```

```{r Differencing}
#find out how many times is needed for differencing 
ns_diff<-nsdiffs(load_deseason)
cat("Number of seasonal differencing needed:", ns_diff) #no need to difference the series
```

```{r Training and testing data}
#training: from 2005-01-01 to 2010-05-30
#testing: from 2010-05-31 to 2011-05-31

#origin series
msts_training<-msts(df_load_processed[,3],seasonal.periods=c(7,365),
                    start=c(2005,01,01), end=c(2010,05,30))


msts_testing<-msts(df_load_processed[,3],seasonal.periods=c(7,365),
                    start=c(2010,05,31), end=c(2011,05,31))

#deseason series
msts_deseason_training<-msts(load_deseason,seasonal.periods=c(7,365),
                    start=c(2005,01,01), end=c(2010,05,30))

msts_deseason_testing<-msts(load_deseason,seasonal.periods=c(7,365),
                    start=c(2010,05,31), end=c(2011,05,31))
```

# One year forecast horizon
```{r ETS}
ETS_fit<-stlf(msts_training,h=365)
```

```{r ARIMA and Fourier terms}
#K=c(2,4)
#fit ARIMA with original time series 
ARIMA_Four_fit_1<-auto.arima(msts_deseason_training,
                             seasonal=FALSE, #because ARIMA can not handle seasonality 
                             xreg=fourier(msts_deseason_training,K=c(2,4)))
#forecast with ARIMA_fit
ARIMA_Four_forecast_1<-forecast(ARIMA_Four_fit_1,
                                xreg=fourier(msts_deseason_training,K=c(2,4),h=365),
                                h=365) 


#K=c(2,12)
#fit ARIMA with original time series 
ARIMA_Four_fit_2<-auto.arima(msts_training,
                             seasonal=FALSE, 
                             xreg=fourier(msts_training,K=c(2,12)))
#forecast with ARIMA_fit
ARIMA_Four_forecast_2<-forecast(ARIMA_Four_fit_2,
                                xreg=fourier(msts_training,K=c(2,12),h=365),
                                h=365) 
```

```{r ARIMA + Fourie + exogenous variable}
#temp
#create time series object 
msts_temp_training<-msts(df[,7], seasonal.periods=c(7,365),
                   start=c(2015,07,01),end=c(2020,12,31))

msts_temp_testing<-msts(df[,7], seasonal.periods=c(7,365),
                   start=c(2021,01,01),end=c(2022,12,31))


#humid
```

```{r Neural Network}
#p=1, P=0 because seasonal=FALSE

#K=c(2,4)
NN_fit_1<-nnetar(msts_deseason_training,
                 p=1,
                 P=0,
                 xreg=fourier(msts_deseason_training,K=c(2,4)))

NN_forecast_1<-forecast(NN_fit_1,
                        xreg=fourier(msts_training,K=c(2,4),h=365), 
                        h=365)

#K=c(2,12)
NN_fit_2<-nnetar(msts_training,
                 p=1,
                 P=0,
                 xreg=fourier(msts_training,K=c(2,12)))

NN_forecast_2<-forecast(NN_fit_2,
                        xreg=fourier(msts_training,K=c(2,12),h=365), 
                        h=365)

```

```{r Plot Forecast Results}
#forecast period 
forecast_start<-start(ARIMA_Four_forecast_1$mean)
forecast_end<-end(ARIMA_Four_forecast_1$mean)
msts_forecast<-window(msts_load, start=forecast_start, end=forecast_end)

#plot forecasting result

#with K=c(2,4)
#add the seasonality back 
ETS_fit$mean<-ETS_fit$mean+load_decompose$seasonal
ARIMA_Four_forecast_1$mean<-ARIMA_Four_forecast_1$mean+load_decompose$seasonal
NN_forecast_1$mean<-NN_forecast_1$mean+load_decompose$seasonal

autoplot(msts_forecast)+
  autolayer(ETS_fit,series="STL+ETS",PI=FALSE)+
  autolayer(ARIMA_Four_forecast_1, series="ARIMA Fourier",PI=FALSE)+
  autolayer(NN_forecast_1, series="Neural Network")

#with K=c(2,12)
autoplot(msts_forecast)+
  autolayer(ETS_fit,series="STL+ETS",PI=FALSE)+
  autolayer(ARIMA_Four_forecast_2, series="ARIMA Fourier",PI=FALSE)+
  autolayer(NN_forecast_2, series="Neural Network")
```

```{r Model Residuals}
resi_ETS<-checkresiduals(ETS_fit)
resi_ARIMA_Four_1<-checkresiduals(ARIMA_Four_forecast_1)
resi_ARIMA_Four_2<-checkresiduals(ARIMA_Four_forecast_2)
resi_NN_forecast_1<-checkresiduals(NN_forecast_1)
resi_NN_forecast_2<-checkresiduals(NN_forecast_2)
```

```{r Accuracy}
#Model1:ETS
scores_ETS<-accuracy(ETS_fit$mean,msts_testing)

#Model2: ARIMA + Fourier, K=c(2,4) 
scores_ARIMA_Four_forecast_1<-accuracy(ARIMA_Four_forecast_1$mean,msts_testing)

#Model3: ARIMA + Fourier, K=c(2,12)
scores_ARIMA_Four_forecast_2<-accuracy(ARIMA_Four_forecast_2$mean,msts_testing)

#Model4: Neural network, K=C(2,4) 
scores_NN_1<-accuracy(NN_forecast_1$mean,msts_testing)

#Model5: Neural network, K=c(2,12)
scores_NN_2<-accuracy(NN_forecast_2$mean,msts_testing)

#create a data frame to store the scores 
scores<-as.data.frame(rbind(scores_ETS,
                            scores_ARIMA_Four_forecast_1,
                            scores_ARIMA_Four_forecast_2,
                            scores_NN_1,
                            scores_NN_2))
row.names(scores)<-c("ETS",
                     "ARIMA+Fourier, K=C(2,4)",
                     "ARIMA+Fourier, K=C(2,12)",
                     "NN, K=C(2,4)",
                     "NN, K=C(2,12)")

#create a comparable table 
kbl(scores, 
    caption = "Forecast Accuracy for Electricity Demand",
    digits = array(5,ncol(scores))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position")

#Model3 has the lowest the RMSE and MAPE
```
